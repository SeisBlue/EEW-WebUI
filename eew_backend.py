import argparse
import bisect
import json
import multiprocessing
import sys
import threading
import time
from datetime import datetime

import numpy as np
import pandas as pd
import PyEW
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi_socketio import SocketManager
from scipy.signal import detrend, iirfilter, sosfilt, zpk2sos
from loguru import logger

# åˆå§‹åŒ– multiprocessing å…±äº«ç‰©ä»¶
manager = multiprocessing.Manager()
wave_buffer = manager.dict()
wave_queue = manager.Queue()
pick_buffer = manager.dict()
report_queue = manager.Queue()
wave_endt = manager.Value("d", 0)
wave_speed_count = manager.Value("i", 0)

app = FastAPI()
# HTTP API çš„ CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# SocketIO çš„ CORSï¼ˆç¨ç«‹è™•ç† WebSocketï¼‰
socket_manager = SocketManager(app=app, cors_allowed_origins="*")

# è¨‚é–±ç®¡ç†ï¼šè¿½è¹¤æ¯å€‹å®¢æˆ¶ç«¯è¨‚é–±çš„æ¸¬ç«™
subscribed_stations = {}  # {session_id: set(station_codes)}

"""
Web Server
"""


@socket_manager.on("connect")
def connect_earthworm(sid, environ):
    socket_manager.emit("connect_init", to=sid)


@socket_manager.on("subscribe_stations")
def handle_subscribe_stations(sid,data):
    """è™•ç†å‰ç«¯è¨‚é–±æ¸¬ç«™è«‹æ±‚"""
    session_id = sid
    stations = data.get("stations", [])

    if stations:
        subscribed_stations[session_id] = set(stations)
        logger.info(
            f"ğŸ“¡ Client {session_id[:8]} subscribed to {len(stations)} stations"
        )
    else:
        # æ¸…ç©ºè¨‚é–±
        if session_id in subscribed_stations:
            del subscribed_stations[session_id]
        logger.info(f"ğŸ“¡ Client {session_id[:8]} unsubscribed from all stations")


@socket_manager.on("disconnect")
def handle_disconnect(sid):
    """å®¢æˆ¶ç«¯æ–·ç·šæ™‚æ¸…ç†è¨‚é–±"""
    session_id = sid
    if session_id in subscribed_stations:
        del subscribed_stations[session_id]
        logger.info(f"ğŸ”Œ Client {session_id[:8]} disconnected, subscription removed")


def _process_wave_data(wave, is_realtime=False):
    """è™•ç†å–®å€‹æ³¢å½¢æ•¸æ“šï¼Œæå–ä¸¦æ ¼å¼åŒ–"""
    waveform_data = wave["data"]

    # é€²è¡Œè¨Šè™Ÿè™•ç†
    processed_data = signal_processing(waveform_data)
    if processed_data is not None:
        waveform_data = processed_data

    if isinstance(waveform_data, np.ndarray):
        waveform_list = waveform_data.tolist()
        pga = float(np.max(np.abs(waveform_data)))
    elif isinstance(waveform_data, list):
        waveform_list = waveform_data
        pga = float(max(abs(x) for x in waveform_data)) if waveform_data else 0.0
    else:
        return None

    return {
        "waveform": waveform_list,
        "pga": pga,
        "status": "active",
        "startt": wave.get("startt", 0),
        "endt": wave.get("endt", 0),
        "samprate": wave.get("samprate", 100),
        "is_realtime": is_realtime,
    }



def signal_processing(waveform):
    try:
        # demean and lowpass filter
        data = detrend(waveform, type="constant")
        data = lowpass(data, freq=10)

        return data

    except Exception as e:
        logger.error(f"signal_processing error: {e}")


def lowpass(data, freq=10, df=100, corners=4):
    """
    Modified form ObsPy Signal Processing
    https://docs.obspy.org/_modules/obspy/signal/filter.html#lowpass
    """
    fe = 0.5 * df
    f = freq / fe

    if f > 1:
        f = 1.0
    z, p, k = iirfilter(corners, f, btype="lowpass", ftype="butter", output="zpk")
    sos = zpk2sos(z, p, k)

    return sosfilt(sos, data)

def wave_emitter():
    """æŒ‰éœ€æ¨é€æ³¢å½¢æ•¸æ“š - åªç™¼é€è¢«è¨‚é–±çš„æ¸¬ç«™"""
    batch_interval = 0.1
    last_send_time = time.time()

    while True:
        try:
            wave_batch = {}
            current_time = time.time()

            # æ”¶é›†ä¸€å®šæ™‚é–“å…§çš„æ‰€æœ‰æ³¢å½¢æ•¸æ“š
            while current_time - last_send_time < batch_interval:
                try:
                    wave = wave_queue.get(timeout=0.05)
                    wave_id = join_id_from_dict(wave, order="NSLC")

                    if "Z" not in wave_id:
                        continue

                    # è™•ç†æ³¢å½¢æ•¸æ“š
                    processed = _process_wave_data(wave, is_realtime=False)
                    if processed:
                        wave_batch[wave_id] = processed

                except:
                    pass

                current_time = time.time()

            # ç™¼é€æ•¸æ“š
            if wave_batch and subscribed_stations:
                all_subscribed = set()
                for stations_set in subscribed_stations.values():
                    all_subscribed.update(stations_set)

                filtered_batch = {}
                for wave_id, wave_data in wave_batch.items():
                    station_code = wave_id.split(".")[1] if "." in wave_id else wave_id
                    if station_code in all_subscribed:
                        filtered_batch[wave_id] = wave_data

                if filtered_batch:
                    timestamp = int(time.time() * 1000)
                    wave_packet = {
                        "waveid": f"batch_{timestamp}",
                        "timestamp": timestamp,
                        "data": filtered_batch,
                    }
                    socket_manager.emit("wave_packet", wave_packet)
                    logger.debug(
                        f"ğŸ“¦ Batch sent: {len(filtered_batch)}/{len(wave_batch)} stations"
                    )

            last_send_time = current_time

        except Exception as e:
            logger.error(f"Error in wave_emitter: {e}")
            time.sleep(0.1)
            continue


def report_emitter():
    while True:
        report_data = report_queue.get()
        if not report_data:
            continue

        socket_manager.emit("report_data", report_data)


def web_server():
    """å•Ÿå‹• Web Server èˆ‡ socket_manager"""
    logger.info("Starting web server...")

    # å•Ÿå‹•èƒŒæ™¯è³‡æ–™ç™¼é€åŸ·è¡Œç·’
    threading.Thread(target=wave_emitter, daemon=True).start()
    threading.Thread(target=report_emitter, daemon=True).start()

    import uvicorn
    uvicorn.run(app, host=args.host, port=args.port)


"""
Earthworm Wave Listener
"""

# Load site info
site_info_file = "/workspace/station/site_info.csv"
try:
    logger.info(f"Loading {site_info_file}...")
    site_info = pd.read_csv(site_info_file)
    constant_dict = site_info.set_index(["Station", "Channel"])["Constant"].to_dict()
    logger.info(f"{site_info_file} loaded")

except FileNotFoundError:
    logger.warning(f"{site_info_file} not found")


def join_id_from_dict(data, order="NSLC"):
    code = {"N": "network", "S": "station", "L": "location", "C": "channel"}
    data_id = ".".join(data[code[letter]] for letter in order)
    return data_id


def convert_to_tsmip_legacy_naming(wave):
    if wave["network"] == "TW":
        wave["network"] = "SM"
        wave["location"] = "01"
    return wave


def get_wave_constant(wave):
    # count to cm/s^2
    try:
        wave_constant = constant_dict[wave["station"], wave["channel"]]

    except Exception as e:
        logger.debug(
            f"{wave['station']} not found in site_info.txt, use default 3.2e-6"
        )
        wave_constant = 3.2e-6

    return wave_constant


def wave_array_init(sample_rate, buffer_time, fill_value):
    return np.full(sample_rate * buffer_time, fill_value=fill_value)


def time_array_init(sample_rate, buffer_time, start_time, end_time, data_length):
    """
    ç”Ÿæˆä¸€å€‹æ™‚é–“åºåˆ—ï¼ŒåŒ…å«å‰å¾Œå…©æ®µ
    å¾Œæ®µå¾ start_time å…§æ’è‡³ end_time (ç¢ºå®šçš„æ™‚é–“åºåˆ—)
    å‰æ®µå¾ start_time å¤–æ’è‡³ buffer é–‹å§‹é» (å¾€å‰é ä¼°çš„æ™‚é–“åºåˆ—)
    """
    return np.append(
        np.linspace(
            start_time - (buffer_time - 1),
            start_time,
            sample_rate * (buffer_time - 1),
        ),
        np.linspace(start_time, end_time, data_length),
    )


def slide_array(array, data):
    array = np.append(array, data)
    return array[data.size :]


def earthworm_wave_listener(buf_ring):
    buffer_time = 30  # è¨­å®šç·©è¡å€ä¿ç•™æ™‚é–“
    sample_rate = 100  # è¨­å®šå–æ¨£ç‡

    # é å…ˆè¨ˆç®—å¸¸æ•¸ï¼Œé¿å…é‡è¤‡æŸ¥è©¢
    wave_constant_cache = {}
    wave_buffer_local = {}  # æœ¬åœ°ç·©å­˜ï¼Œæ¸›å°‘ Manager.dict è¨ªå•

    while True:
        if not earthworm.mod_sta():
            continue

        wave = earthworm.get_wave(buf_ring)
        if not wave:
            continue

        # å¿«é€Ÿæ™‚é–“æª¢æŸ¥ï¼ˆæœ€æ—©éæ¿¾ï¼‰
        wave_endt_val = wave["endt"]
        current_time = time.time()
        if wave_endt_val < current_time - 3 or wave_endt_val > current_time + 1:
            continue

        # å¾—åˆ°æœ€æ–°çš„ wave çµæŸæ™‚é–“
        wave_endt.value = wave_endt_val

        try:
            # å…§è¯ convert_to_tsmip_legacy_namingï¼Œé¿å…å‡½æ•¸èª¿ç”¨
            network = wave["network"]
            if network == "TW":
                network = "SM"
                location = "01"
            else:
                location = wave["location"]

            station = wave["station"]
            channel = wave["channel"]

            # å…§è¯ join_id_from_dictï¼Œé¿å…å­—ä¸²æ“ä½œé–‹éŠ·
            wave_id = f"{network}.{station}.{location}.{channel}"

            # å¿«é€Ÿæª¢æŸ¥æ˜¯å¦ç‚º Z é€šé“ï¼ˆæå‰åˆ¤æ–·ï¼‰
            is_z_channel = "Z" in wave_id

            # ä½¿ç”¨ç·©å­˜ç²å– wave_constant
            cache_key = (station, channel)
            if cache_key not in wave_constant_cache:
                try:
                    wave_constant_cache[cache_key] = constant_dict[cache_key]
                except:
                    wave_constant_cache[cache_key] = 3.2e-6

            # ç›´æ¥åœ¨åŸæ•¸æ“šä¸Šä¹˜ä»¥å¸¸æ•¸ï¼Œé¿å…è¤‡è£½
            wave_data = wave["data"] * wave_constant_cache[cache_key]
            wave["data"] = wave_data

            # å°‡ wave_id åŠ å…¥ wave_queue çµ¦ wave_emitter ç™¼é€è‡³å‰ç«¯
            if is_z_channel:
                wave_queue.put(wave)

            # add new trace to buffer - ä½¿ç”¨æœ¬åœ°ç·©å­˜
            if wave_id not in wave_buffer_local:
                # æª¢æŸ¥æ˜¯å¦åœ¨å…±äº« buffer ä¸­
                if wave_id not in wave_buffer.keys():
                    # wave_buffer åˆå§‹åŒ–æ™‚å…¨éƒ¨å¡«å…¥ wave çš„å¹³å‡å€¼
                    init_array = wave_array_init(
                        sample_rate, buffer_time, fill_value=wave_data.mean()
                    )
                    wave_buffer[wave_id] = init_array
                    wave_buffer_local[wave_id] = init_array
                else:
                    wave_buffer_local[wave_id] = wave_buffer[wave_id]

            # æ›´æ–° buffer
            updated_array = slide_array(wave_buffer_local[wave_id], wave_data)
            wave_buffer_local[wave_id] = updated_array
            wave_buffer[wave_id] = updated_array

            wave_speed_count.value += 1

        except Exception as e:
            logger.error(f"earthworm_wave_process error {e}")


"""
Earthworm Pick Listener
"""


def parse_pick_msg(pick_msg):
    pick_msg_column = pick_msg.split()
    try:
        pick = {
            "station": pick_msg_column[0],
            "channel": pick_msg_column[1],
            "network": pick_msg_column[2],
            "location": pick_msg_column[3],
            "lon": pick_msg_column[4],
            "lat": pick_msg_column[5],
            "pga": pick_msg_column[6],
            "pgv": pick_msg_column[7],
            "pd": pick_msg_column[8],
            "tc": pick_msg_column[9],  # Average period
            "pick_time": pick_msg_column[10],
            "weight": pick_msg_column[11],  # 0:best 5:worst
            "instrument": pick_msg_column[12],  # 1:Acc 2:Vel
            "update_sec": pick_msg_column[13],  # sec after pick
        }

        pick["pickid"] = join_id_from_dict(pick, order="NSLC")

        return pick

    except IndexError as e:
        logger.error(f"pick_msg parsing error: {pick_msg_column}, {e}")


def earthworm_pick_listener(buf_ring):
    """
    ç›£çœ‹ pick ring çš„è¨Šæ¯ï¼Œä¸¦å°‡ pick åŠ å…¥ pick_buffer
    pick msg çš„æ™‚é–“çª—ç‚º p æ³¢å¾Œ 2-10 ç§’
    ref: pick_ew_new/pick_ra_0709.c line 283
    """
    event_window = 10
    while True:
        try:
            # è¶…æ™‚ç§»é™¤ pick
            for pick_id, buffer_pick in pick_buffer.items():
                if float(buffer_pick["sys_time"]) + event_window < time.time():
                    pick_buffer.__delitem__(pick_id)
                    logger.debug(f"delete pick: {pick_id}")
        except BrokenPipeError:
            break

        except Exception as e:
            logger.error(f"delete pick error: {pick_id}, {e}")

        # å–å¾— pick msg
        pick_msg = earthworm.get_msg(buf_ring=buf_ring, msg_type=0)
        if not pick_msg:
            time.sleep(0.00001)
            continue
        logger.debug(f"{pick_msg}")

        # PickRing trace gap å¤ªå¤§æœƒæœ‰ Restarting çš„è¨Šæ¯
        if "Restarting" in pick_msg:
            continue

        # PickRing çš„æœªçŸ¥çŸ­è¨Šæ¯ï¼Œå¦‚ï¼š1732070774 124547
        if len(pick_msg.split()) < 13:
            continue

        try:
            pick_data = parse_pick_msg(pick_msg)
            pick_id = join_id_from_dict(pick_data, order="NSLC")

            # è·³éç¨‹å¼å•Ÿå‹•å‰æ®˜ç•™åœ¨ shared memory çš„ Pick
            if time.time() > float(pick_data["pick_time"]) + 10:
                continue

            # upsec ç‚º 2 ç§’æ™‚åŠ å…¥ pick
            if pick_data["update_sec"] == "2":
                print(pick_msg)
                sys.stdout.flush()

                # ä»¥ç³»çµ±æ™‚é–“ä½œç‚ºæ™‚é–“æˆ³è¨˜
                pick_data["sys_time"] = time.time()
                pick_buffer[pick_id] = pick_data
                logger.debug(f"add pick: {pick_id}")

        except Exception as e:
            logger.error(f"earthworm_pick_listener error: {pick_msg}, {e}")
            continue
        time.sleep(0.00001)


"""
Earthworm EEW Listener
"""


def earthworm_eew_listener(buf_ring):
    while True:
        try:
            # å–å¾— pick msg
            eew_msg = earthworm.get_msg(buf_ring=buf_ring, msg_type=0)
            if not eew_msg:
                time.sleep(0.00001)
                continue
            print(eew_msg)
            sys.stdout.flush()
            logger.debug(f"{eew_msg}")

        except Exception as e:
            logger.error(f"earthworm_eew_listener error: {eew_msg}, {e}")
            continue
        time.sleep(0.00001)


# Load target station
target_file = "/workspace/station/eew_target.csv"
try:
    logger.info(f"Loading {target_file}...")
    target_df = pd.read_csv(target_file)
    target_dict = target_df.to_dict(orient="records")
    logger.info(f"{target_file} loaded")

except FileNotFoundError:
    logger.error(f"{target_file} not found")

# Load all stations from site_info.csv (for secondary stations display)
all_stations_dict = []
site_info_file = "/workspace/station/site_info.csv"
try:
    logger.info(f"Loading {site_info_file}...")
    site_info_df = pd.read_csv(site_info_file)

    # åªå– HLZ é€šé“ä¸”ä»åœ¨é‹ä½œçš„æ¸¬ç«™ï¼ˆEnd_time = 2599-12-31ï¼‰
    active_stations = site_info_df[
        (site_info_df["Channel"] == "HLZ") & (site_info_df["End_time"] == "2599-12-31")
    ].copy()

    # å»é‡ï¼ˆåŒä¸€æ¸¬ç«™å¯èƒ½æœ‰å¤šæ¢è¨˜éŒ„ï¼‰
    active_stations = active_stations.drop_duplicates(subset=["Station"])

    # è½‰æ›ç‚ºå­—å…¸æ ¼å¼
    all_stations_dict = (
        active_stations[["Station", "Latitude", "Longitude"]]
        .rename(
            columns={
                "Station": "station",
                "Latitude": "latitude",
                "Longitude": "longitude",
            }
        )
        .to_dict(orient="records")
    )

    logger.info(
        f"Loaded {len(all_stations_dict)} active stations from {site_info_file}"
    )

except FileNotFoundError:
    logger.warning(
        f"{site_info_file} not found, secondary stations will not be available"
    )
except Exception as e:
    logger.error(f"Error loading {site_info_file}: {e}")



def calculate_intensity(pga, pgv=None, label=False):
    try:
        intensity_label = ["0", "1", "2", "3", "4", "5-", "5+", "6-", "6+", "7"]
        pga_level = np.log10(
            [1e-5, 0.008, 0.025, 0.080, 0.250, 0.80, 1.4, 2.5, 4.4, 8.0]
        )  # log10(m/s^2)

        pgv_level = np.log10(
            [1e-5, 0.002, 0.007, 0.019, 0.057, 0.15, 0.3, 0.5, 0.8, 1.4]
        )  # log10(m/s)

        pga_intensity = bisect.bisect(pga_level, pga) - 1
        intensity = pga_intensity

        if pga > pga_level[5] and pgv is not None:
            pgv_intensity = bisect.bisect(pgv_level, pgv) - 1
            if pgv_intensity > pga_intensity:
                intensity = pgv_intensity

        if label:
            return intensity_label[intensity]

        else:
            return intensity

    except Exception as e:
        logger.error(f"calculate_intensity error: {e}")



def loading_animation(pick_threshold):
    pick_counts = len(pick_buffer)
    loading_chars = ["-", "\\", "|", "/"]

    # ç„¡é™å¾ªç’°é¡¯ç¤º loading å‹•ç•«
    wave_speed_count.value = 0
    start_time = time.time()
    for char in loading_chars:
        # æ¸…é™¤ä¸Šä¸€å€‹å­—ç¬¦
        sys.stdout.write("\r" + " " * 30 + "\r")
        sys.stdout.flush()

        wave_count = len(wave_buffer)

        wave_timestring = datetime.fromtimestamp(float(wave_endt.value)).strftime(
            "%Y-%m-%d %H:%M:%S.%f"
        )

        delay = time.time() - wave_endt.value

        delta = time.time() - start_time
        wave_process_rate = wave_speed_count.value / delta if delta > 0 else 0

        # é¡¯ç¤ºç›®å‰çš„ loading å­—ç¬¦
        sys.stdout.write(
            f"{wave_count} waves: {wave_timestring[:-3]} rate: {wave_process_rate:.3f} lag:{delay:.3f}s picks:{pick_counts}/{pick_threshold} {char} "
        )
        sys.stdout.flush()
        time.sleep(0.1)

def convert_intensity(value):
    if value.endswith("+"):
        return float(value[:-1]) + 0.25
    elif value.endswith("-"):
        return float(value[:-1]) - 0.25
    else:
        return float(value)


def reporter():
    """
    ç´¯ç©ç™¼é€é è­¦ä¹‹æ¸¬ç«™ï¼Œè¾¨è­˜å…¶è¡Œæ”¿å€ï¼Œæ¯éš”ä¸€ç§’æª¢æŸ¥æ˜¯å¦æœ‰æ–°å¢è¡Œæ”¿å€ï¼Œé¿å…åœ¨çŸ­æ™‚é–“å…§é‡è¤‡ç™¼é€è­¦å ±ï¼Œå¦‚æœ pick < 5 å‰‡é‡ç½®
    """
    station_list = []
    station_info = {}
    for target in target_dict:
        station_list.append(target["station"])
        station_info[target["station"]] = {
            "station_zh": target["station_zh"],
            "county": target["county"],
        }

    alarm_county = {}
    past_alarm_county = {}
    new_alarm_county = {}
    start_time = time.time()
    while True:
        report = report_queue.get()

        for station in station_list:
            intensity = report.get(station, "N/A")
            if intensity in ["4", "5-", "5+", "6-", "6+", "7"]:
                county = station_info[station]["county"]
                if county not in alarm_county:
                    alarm_county[county] = intensity
                else:
                    alarm_county[county] = max(
                        alarm_county[county], intensity, key=convert_intensity
                    )

        if time.time() - start_time < 1:
            time.sleep(0.1)
            continue

        for county, intensity in alarm_county.items():
            if county not in past_alarm_county:
                new_alarm_county[county] = intensity

            elif convert_intensity(intensity) > convert_intensity(
                past_alarm_county[county]
            ):
                new_alarm_county[county] = intensity

        if new_alarm_county:
            report["alarm_county"] = alarm_county
            report["new_alarm_county"] = new_alarm_county
            format_report = format_earthquake_report(report)
            print(format_report)
            sys.stdout.flush()

            with open(
                f"/workspace/logs/format_report/text_report_{report['format_time']}.log",
                "a",
            ) as f:
                f.write(format_report + "\n")


            past_alarm_county.update(new_alarm_county)
            new_alarm_county = {}

        start_time = time.time()

        if len(pick_buffer) < 5:
            alarm_county = {}
            new_alarm_county = {}
            past_alarm_county = {}


def format_earthquake_report(raw_report):
    report_lines = []
    report_lines.append("--------------------------------------------------")
    report_lines.append("ã€åœ°éœ‡é è­¦å ±å‘Šã€‘")
    report_lines.append("")

    # æ‘˜è¦éƒ¨åˆ†
    report_lines.append(f"è­¦å ±æ™‚é–“ï¼š{raw_report['report_time']}")
    report_lines.append("")
    if "new_alarm_county" in raw_report:
        report_lines.append("ã€æ–°å¢è­¦å ±ã€‘")
        county_list = []
        for county, intensity in raw_report["new_alarm_county"].items():
            county_list.append([intensity, county])
        county_list = sorted(
            county_list, key=lambda x: convert_intensity(x[0]), reverse=True
        )
        for intensity, county in county_list:
            report_lines.append(f"{county}ï¼š{intensity} ç´šä»¥ä¸Š")

        report_lines.append("")

    # è©³ç´°æŠ€è¡“è³‡è¨Šéƒ¨åˆ†
    report_lines.append("ã€ç³»çµ±è³‡è¨Šã€‘")
    report_lines.append(f"æ³¢å½¢å»¶é²ï¼š{raw_report['wave_lag']:.2f} ç§’")
    report_lines.append(f"ç´¯ç©æ³¢å‹ï¼š{raw_report['wave_time']:.2f} ç§’")
    report_lines.append(f"è¨ˆç®—æ™‚é–“ï¼š{raw_report['run_time']:.4f} ç§’")
    report_lines.append("")
    report_lines.append("--------------------------------------------------")

    return "\n".join(report_lines)


if __name__ == "__main__":
    logger.info("TTSAM Realtime Start")
    parser = argparse.ArgumentParser()
    parser.add_argument("--host", type=str, default="0.0.0.0", help="web server ip")
    parser.add_argument("--port", type=int, default=5001, help="web server port")
    parser.add_argument(
        "--env",
        type=str,
        default="test",
        choices=["cwa", "test", "jimmy"],
        help="set environment",
    )
    parser.add_argument(
        "--verbose-level",
        type=str,
        default="INFO",
        help="change verbose level: ERROR, WARNING, INFO, DEBUG",
    )
    parser.add_argument(
        "--log-level",
        type=str,
        default="INFO",
        help="change log level: ERROR, WARNING, INFO, DEBUG",
    )
    args = parser.parse_args()
    processes = []

    # get config
    config_file = "ttsam_config.json"
    try:
        config = json.load(open(config_file, "r"))
        logger.info(f"{config_file} loaded")
    except FileNotFoundError:
        config = {
            "mqtt": {
                "username": "ttsam",
                "password": "ttsam",
                "host": "0.0.0.0",
                "port": 1883,
                "topic": "ttsam",
            },
            "discord": {
                "webhook_url": "webhook",
                "proxies": {"http": "proxy", "https": "proxy"},
            },
        }
        logger.warning(f"{config_file} not found, using default config")

    # é…ç½®æ—¥èªŒè¨­ç½®
    logger.remove()
    logger.add(sys.stderr, level=args.verbose_level, backtrace=True, diagnose=True)
    logger.add(
        "/workspace/logs/ttsam_error.log",
        rotation="1 week",
        level=args.log_level,
        enqueue=True,
        backtrace=True,
    )

    earthworm_param = {
        "test": {
            "inst_id": 255,
            "wave": {"WAVE_RING_CWASN": 1000, "WAVE_RING_TSMIP": 1030},
            "pick": {"PICK_RING": 1005},
            "eew": {"EEW_RING": 1035},
        },
        "jimmy": {
            "inst_id": 255,
            "wave": {"WAVE_RING_TSMIP": 1034},
            "pick": {"PICK_RING": 1005},
            "eew": {},
        },
        "cwa": {
            "inst_id": 52,
            "wave": {"WAVE_RING_TSMIP": 1034},
            "pick": {"PICK_RING": 1005},
            "eew": {},
        },
    }
    ring_order = []  # æ–°å¢ï¼šè¿½è¹¤ ring æ·»åŠ é †åº
    earthworm = PyEW.EWModule(
        def_ring=1000,
        mod_id=2,
        inst_id=earthworm_param[args.env]["inst_id"],
        hb_time=30,
        db=False,
    )

    # æ·»åŠ  wave ringsï¼ˆæ ¹æ“š env å‹•æ…‹æ·»åŠ ï¼‰
    for ring_name, ring_id in earthworm_param[args.env]["wave"].items():
        earthworm.add_ring(ring_id)
        ring_order.append(ring_name)
        buf_ring = len(ring_order) - 1
        processes.append(
            multiprocessing.Process(target=earthworm_wave_listener, kwargs={"buf_ring": buf_ring})
        )
        logger.info(f"Added ring{len(ring_order) - 1}: {ring_name} with ID {ring_id}")

    # æ·»åŠ  pick ringsï¼ˆæ ¹æ“š env å‹•æ…‹æ·»åŠ ï¼‰
    for ring_name, ring_id in earthworm_param[args.env]["pick"].items():
        earthworm.add_ring(ring_id)
        ring_order.append(ring_name)
        buf_ring = len(ring_order) - 1
        processes.append(
            multiprocessing.Process(target=earthworm_pick_listener, kwargs={"buf_ring": buf_ring})
        )
        logger.info(f"Added ring{len(ring_order) - 1}: {ring_name} with ID {ring_id}")

    # æ·»åŠ  eew ringsï¼ˆæ ¹æ“š env å‹•æ…‹æ·»åŠ ï¼‰
    for ring_name, ring_id in earthworm_param[args.env]["eew"].items():
        earthworm.add_ring(ring_id)
        ring_order.append(ring_name)
        buf_ring = len(ring_order) - 1
        processes.append(
            multiprocessing.Process(target=earthworm_eew_listener,
                                    kwargs={"buf_ring": buf_ring})
        )
        logger.info(
            f"Added ring{len(ring_order) - 1}: {ring_name} with ID {ring_id}")

    logger.info(f"{args.env} env, inst_id = {earthworm_param[args.env]['inst_id']}")


    processes.append(multiprocessing.Process(target=reporter))

    for p in processes:
        p.start()
